{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13192b45beef0a69",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import torch as pt\n",
    "pt.cuda.is_available()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f01551e27774cbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T18:23:39.574427Z",
     "start_time": "2024-08-01T18:23:37.514432Z"
    },
    "collapsed": false
   },
   "source": [
    "#!pip install dinov2\n",
    "!pip install --upgrade  git+https://github.com/facebookresearch/dinov2.git"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "eb5c8577-7dff-41b1-9b04-2dca12940e02",
   "metadata": {},
   "source": [
    "# Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "febdf412-5ad0-4bbc-9530-754f92dcc491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T18:23:41.202048Z",
     "start_time": "2024-08-01T18:23:41.191913Z"
    }
   },
   "source": [
    "# import sys\n",
    "# \n",
    "# INSTALL = True # Switch this to install dependencies\n",
    "# if INSTALL: # Try installing package with extras\n",
    "#     REPO_URL = \"https://raw.githubusercontent.com/facebookresearch/dinov2/main/requirements.txt\"\n",
    "#     REPO_EXTRAS = \"https://raw.githubusercontent.com/facebookresearch/dinov2/main/requirements-extras.txt\"\n",
    "#     !{sys.executable} -m pip install -r {REPO_URL} --extra-index-url https://download.pytorch.org/whl/cu117  --extra-index-url https://pypi.nvidia.com\n",
    "#     !{sys.executable} -m pip install -r {REPO_EXTRAS} --extra-index-url https://download.pytorch.org/whl/cu117  --extra-index-url https://pypi.nvidia.com\n",
    "# else:\n",
    "#     REPO_PATH = \"<FIXME>\" # Specify a local path to the repository (or use installed package instead)\n",
    "#     sys.path.append(REPO_PATH)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "efdf378b-0591-4879-9db6-6a4ab582d49f",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90223c04-e7da-4738-bb16-d4f7025aa3eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T18:46:04.483692Z",
     "start_time": "2024-08-01T18:46:02.598952Z"
    }
   },
   "source": [
    "import math\n",
    "import itertools\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from mmseg.apis import init_segmentor, inference_segmentor\n",
    "\n",
    "import dinov2.eval.segmentation.models\n",
    "\n",
    "\n",
    "class CenterPadding(torch.nn.Module):\n",
    "    def __init__(self, multiple):\n",
    "        super().__init__()\n",
    "        self.multiple = multiple\n",
    "\n",
    "    def _get_pad(self, size):\n",
    "        new_size = math.ceil(size / self.multiple) * self.multiple\n",
    "        pad_size = new_size - size\n",
    "        pad_size_left = pad_size // 2\n",
    "        pad_size_right = pad_size - pad_size_left\n",
    "        return pad_size_left, pad_size_right\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def forward(self, x):\n",
    "        pads = list(itertools.chain.from_iterable(self._get_pad(m) for m in x.shape[:1:-1]))\n",
    "        output = F.pad(x, pads)\n",
    "        return output\n",
    "\n",
    "\n",
    "def create_segmenter(cfg, backbone_model):\n",
    "    model = init_segmentor(cfg)\n",
    "    model.backbone.forward = partial(\n",
    "        backbone_model.get_intermediate_layers,\n",
    "        n=cfg.model.backbone.out_indices,\n",
    "        reshape=True,\n",
    "    )\n",
    "    if hasattr(backbone_model, \"patch_size\"):\n",
    "        model.backbone.register_forward_pre_hook(lambda _, x: CenterPadding(backbone_model.patch_size)(x[0]))\n",
    "    model.init_weights()\n",
    "    return model"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a5724efc-b2b8-46ed-94e1-7fee59a39ed9",
   "metadata": {},
   "source": [
    "## Load pretrained backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d51b932-1157-45ce-997f-572ad417a12f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:27.048587Z",
     "start_time": "2024-05-06T18:54:26.223926Z"
    }
   },
   "source": [
    "BACKBONE_SIZE = \"small\" # in (\"small\", \"base\", \"large\" or \"giant\")\n",
    "\n",
    "\n",
    "backbone_archs = {\n",
    "    \"small\": \"vits14\",\n",
    "    \"base\": \"vitb14\",\n",
    "    \"large\": \"vitl14\",\n",
    "    \"giant\": \"vitg14\",\n",
    "}\n",
    "backbone_arch = backbone_archs[BACKBONE_SIZE]\n",
    "backbone_name = f\"dinov2_{backbone_arch}\"\n",
    "\n",
    "backbone_model = torch.hub.load(repo_or_dir=\"facebookresearch/dinov2\", model=backbone_name)\n",
    "backbone_model.eval()\n",
    "backbone_model.cuda()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c1c90501-d6ef-436e-b1a1-72e63b0534e3",
   "metadata": {},
   "source": [
    "## Load pretrained segmentation head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0bf0b7f-ad98-4cfb-8120-f076df8f8933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:27.233588Z",
     "start_time": "2024-05-06T18:54:27.049348Z"
    }
   },
   "source": [
    "import urllib\n",
    "\n",
    "import mmcv\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "\n",
    "def load_config_from_url(url: str) -> str:\n",
    "    with urllib.request.urlopen(url) as f:\n",
    "        return f.read().decode()\n",
    "\n",
    "\n",
    "HEAD_SCALE_COUNT = 3 # more scales: slower but better results, in (1,2,3,4,5)\n",
    "HEAD_DATASET = \"voc2012\" # in (\"ade20k\", \"voc2012\")\n",
    "HEAD_TYPE = \"ms\" # in (\"ms, \"linear\")\n",
    "\n",
    "\n",
    "DINOV2_BASE_URL = \"https://dl.fbaipublicfiles.com/dinov2\"\n",
    "head_config_url = f\"{DINOV2_BASE_URL}/{backbone_name}/{backbone_name}_{HEAD_DATASET}_{HEAD_TYPE}_config.py\"\n",
    "head_checkpoint_url = f\"{DINOV2_BASE_URL}/{backbone_name}/{backbone_name}_{HEAD_DATASET}_{HEAD_TYPE}_head.pth\"\n",
    "\n",
    "cfg_str = load_config_from_url(head_config_url)\n",
    "cfg = mmcv.Config.fromstring(cfg_str, file_format=\".py\")\n",
    "if HEAD_TYPE == \"ms\":\n",
    "    cfg.data.test.pipeline[1][\"img_ratios\"] = cfg.data.test.pipeline[1][\"img_ratios\"][:HEAD_SCALE_COUNT]\n",
    "    print(\"scales:\", cfg.data.test.pipeline[1][\"img_ratios\"])\n",
    "\n",
    "model = create_segmenter(cfg, backbone_model=backbone_model)\n",
    "load_checkpoint(model, head_checkpoint_url, map_location=\"cpu\")\n",
    "model.cuda()\n",
    "model.eval()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc1b106-d28c-41cc-9ddd-f558d66a4715",
   "metadata": {},
   "source": [
    "## Load sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44511634-8243-4662-a512-4531014adb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:27.245786Z",
     "start_time": "2024-05-06T18:54:27.234135Z"
    }
   },
   "source": [
    "import urllib\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def load_image_from_url(url: str) -> Image:\n",
    "    with urllib.request.urlopen(url) as f:\n",
    "        return Image.open(f).convert(\"RGB\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ab14489ff4ded45a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T23:55:24.985809Z",
     "start_time": "2024-05-06T23:55:24.923446Z"
    }
   },
   "source": [
    "# EXAMPLE_IMAGE_URL = \"https://dl.fbaipublicfiles.com/dinov2/images/example.jpg\"\n",
    "\n",
    "# image = load_image_from_url(EXAMPLE_IMAGE_URL)\n",
    "\n",
    "#image = Image.open(\"woman-and-dog.jpg\").convert(\"RGB\")\n",
    "image1 = Image.open(\"img/input/frame_0015.png\").convert(\"RGB\")\n",
    "display(image1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4695d60437da2255",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:27.372029Z",
     "start_time": "2024-05-06T18:54:27.308511Z"
    }
   },
   "source": [
    "image2 = Image.open(\"img/input/frame_0016.png\").convert(\"RGB\")\n",
    "display(image2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7e3240cb-54d0-438d-99e8-8c1af534f830",
   "metadata": {},
   "source": [
    "## Semantic segmentation on sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49226d5b-83fc-4cfb-ba06-407bb2c0d96f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:27.395172Z",
     "start_time": "2024-05-06T18:54:27.372946Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "import dinov2.eval.segmentation.utils.colormaps as colormaps\n",
    "\n",
    "\n",
    "DATASET_COLORMAPS = {\n",
    "    \"ade20k\": colormaps.ADE20K_COLORMAP,\n",
    "    \"voc2012\": colormaps.VOC2012_COLORMAP,\n",
    "}\n",
    "\n",
    "\n",
    "def render_segmentation(segmentation_logits, dataset):\n",
    "    colormap = DATASET_COLORMAPS[dataset]\n",
    "    colormap_array = np.array(colormap, dtype=np.uint8)\n",
    "    segmentation_values = colormap_array[segmentation_logits + 1]\n",
    "    return Image.fromarray(segmentation_values)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c19fa407e7be7b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:31.607361Z",
     "start_time": "2024-05-06T18:54:27.396060Z"
    }
   },
   "source": [
    "array1 = np.array(image1)[:, :, ::-1] # BGR\n",
    "segmentation_logits1 = inference_segmentor(model, array1)[0]\n",
    "segmented_image1 = render_segmentation(segmentation_logits1, HEAD_DATASET)\n",
    "display(segmented_image1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bccc896482e6fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:35.427947Z",
     "start_time": "2024-05-06T18:54:31.608072Z"
    }
   },
   "source": [
    "array2 = np.array(image2)[:, :, ::-1] # BGR\n",
    "segmentation_logits2 = inference_segmentor(model, array2)[0]\n",
    "segmented_image2 = render_segmentation(segmentation_logits2, HEAD_DATASET)\n",
    "display(segmented_image2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b839bf21d2ab8dbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T23:56:10.780944Z",
     "start_time": "2024-05-06T23:56:10.720414Z"
    }
   },
   "source": [
    "from torchvision.transforms import v2\n",
    "transforms = v2.Compose([\n",
    "    v2.ToTensor(),  # Convert to tensor, only needed if you had a PIL image\n",
    "    v2.ToDtype(torch.float32),  # optional, most input are already uint8 at this point\n",
    "    # ...\n",
    "    v2.Resize(antialias=True, size=(224,224)),  # Or Resize(antialias=True)\n",
    "    # ...\n",
    "    #v2.ToDtype(torch.float32),  # Normalize expects float input\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "image1 = torch.from_numpy(array1.copy()).permute(2,0,1).cuda()\n",
    "print(image1.shape)\n",
    "image1 = transforms(image1)\n",
    "print(image1.shape)\n",
    "image1 = torch.unsqueeze(image1, 0)\n",
    "print(image1.shape)\n",
    "backbone_model(image1)\n",
    "print(backbone_model.get_intermediate_layers(image1)[0].shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "560d16883c17c56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:35.482252Z",
     "start_time": "2024-05-06T18:54:35.451397Z"
    }
   },
   "source": [
    "image2 = torch.from_numpy(array2.copy()).permute(2,0,1).cuda()\n",
    "print(image2.shape)\n",
    "image2 = transforms(image2)\n",
    "print(image2.shape)\n",
    "image2 = torch.unsqueeze(image2, 0)\n",
    "print(image2.shape)\n",
    "backbone_model(image2)\n",
    "print(backbone_model.get_intermediate_layers(image2)[0].shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8b15d59302ef75b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:35.494611Z",
     "start_time": "2024-05-06T18:54:35.482941Z"
    }
   },
   "source": [
    "# inference_segmentor(model, array, return_datasamples=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b5da0849b5ae69a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:35.507639Z",
     "start_time": "2024-05-06T18:54:35.495507Z"
    }
   },
   "source": [
    "array1.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84ba67122a51c23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:35.524760Z",
     "start_time": "2024-05-06T18:54:35.508266Z"
    }
   },
   "source": [
    "nlayers1 = np.unique(segmentation_logits1)\n",
    "layers1 = np.zeros([nlayers1.size, array1.shape[0], array1.shape[1]])\n",
    "print(nlayers1)\n",
    "print(layers1.shape)\n",
    "for i,_ in enumerate(nlayers1):\n",
    "    layers1[i, :, :] = segmentation_logits1 == nlayers1[i]\n",
    "print(layers1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1242024fb53ce15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:35.542017Z",
     "start_time": "2024-05-06T18:54:35.525436Z"
    }
   },
   "source": [
    "nlayers2 = np.unique(segmentation_logits2)\n",
    "layers2 = np.zeros([nlayers2.size, array2.shape[0], array2.shape[1]])\n",
    "print(nlayers2)\n",
    "print(layers2.shape)\n",
    "for i,_ in enumerate(nlayers2):\n",
    "    layers2[i, :, :] = segmentation_logits2 == nlayers2[i]\n",
    "print(layers2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9275530afecaed28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:35.556026Z",
     "start_time": "2024-05-06T18:54:35.542666Z"
    }
   },
   "source": [
    "layers1 = np.moveaxis(layers1, 0, -1)\n",
    "layers1 = layers1.astype(np.uint8)\n",
    "layers1 = layers1*255\n",
    "layers1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "256815b70a34b854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:35.569725Z",
     "start_time": "2024-05-06T18:54:35.556577Z"
    }
   },
   "source": [
    "layers2 = np.moveaxis(layers2, 0, -1)\n",
    "layers2 = layers2.astype(np.uint8)\n",
    "layers2 = layers2*255\n",
    "layers2"
   ],
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T18:20:32.613841Z",
     "start_time": "2024-08-19T18:20:32.608544Z"
    }
   },
   "cell_type": "code",
   "source": "from PIL import Image",
   "id": "52e5f67c030f13e7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "b301037a35a8aa7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T18:20:17.708149Z",
     "start_time": "2024-08-19T18:20:17.688009Z"
    }
   },
   "source": [
    "im = Image.fromarray(layers1)\n",
    "im.save(\"img/output/frame_0015_seg.png\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m----> 2\u001B[0m im \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(\u001B[43mlayers1\u001B[49m)\n\u001B[1;32m      3\u001B[0m im\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg/output/frame_0015_seg.png\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'layers1' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dcb6715bf6ad1e8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:54:35.616390Z",
     "start_time": "2024-05-06T18:54:35.595038Z"
    }
   },
   "source": [
    "im = Image.fromarray(layers2)\n",
    "im.save(\"img/output/frame_0016_seg.png\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de9727433b8f3950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:10:34.859046Z",
     "start_time": "2024-05-06T19:10:34.845777Z"
    }
   },
   "source": [
    "layers2.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26a34b8b1d454311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:35:03.237680Z",
     "start_time": "2024-05-06T19:35:03.224275Z"
    }
   },
   "source": [
    "type(layers2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9fff93bb3e1047ab",
   "metadata": {},
   "source": [
    "## Modify original image using segmentation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3411c6aab3cd9822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T00:32:38.887677Z",
     "start_time": "2024-05-07T00:32:38.866397Z"
    }
   },
   "source": [
    "np.unique(segmentation_logits1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "872e3df72e395947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T18:19:40.312720Z",
     "start_time": "2024-08-19T18:19:40.276990Z"
    }
   },
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6746f680ec350f1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T18:19:44.259942Z",
     "start_time": "2024-08-19T18:19:44.039412Z"
    }
   },
   "source": [
    "def modify_image_segmentation_based(img_name):\n",
    "    image = Image.open(f\"img/input/{img_name}.png\").convert(\"RGB\")\n",
    "    imagen_modificada = np.copy(np.array(image).astype(np.uint8))\n",
    "    coordenadas_objeto1 = np.where(segmentation_logits1 == 15)\n",
    "    coordenadas_objeto2 = np.where(segmentation_logits1 == 16)\n",
    "    for y, x in zip(coordenadas_objeto1[0], coordenadas_objeto1[1]):\n",
    "        imagen_modificada[y, x] = np.clip(imagen_modificada[y, x] * 1.3, 0, 255)\n",
    "\n",
    "    for y, x in zip(coordenadas_objeto2[0], coordenadas_objeto2[1]):\n",
    "        imagen_modificada[y, x] = np.clip(imagen_modificada[y, x] + 20, 0, 255)\n",
    "        \n",
    "    cv2.imwrite(f\"img/output/{img_name}_seg_steroids.png\", imagen_modificada[:, :, ::-1])"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "c81af02a80bab176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T18:20:35.243098Z",
     "start_time": "2024-08-19T18:20:35.207145Z"
    }
   },
   "source": [
    "modify_image_segmentation_based(\"frame_0015\")\n",
    "modify_image_segmentation_based(\"frame_0016\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segmentation_logits1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodify_image_segmentation_based\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mframe_0015\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m modify_image_segmentation_based(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframe_0016\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[2], line 4\u001B[0m, in \u001B[0;36mmodify_image_segmentation_based\u001B[0;34m(img_name)\u001B[0m\n\u001B[1;32m      2\u001B[0m image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg/input/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimg_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m imagen_modificada \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcopy(np\u001B[38;5;241m.\u001B[39marray(image)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint8))\n\u001B[0;32m----> 4\u001B[0m coordenadas_objeto1 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(\u001B[43msegmentation_logits1\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m15\u001B[39m)\n\u001B[1;32m      5\u001B[0m coordenadas_objeto2 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(segmentation_logits1 \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m16\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m y, x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(coordenadas_objeto1[\u001B[38;5;241m0\u001B[39m], coordenadas_objeto1[\u001B[38;5;241m1\u001B[39m]):\n",
      "\u001B[0;31mNameError\u001B[0m: name 'segmentation_logits1' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5a30350ee380168a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T00:22:28.902633Z",
     "start_time": "2024-05-07T00:19:05.652364Z"
    }
   },
   "source": [
    "import cv2\n",
    "window_name = 'image'\n",
    "cv2.imshow(window_name, imagen_modificada[:, :, ::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5b1e16e47ef48bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T23:46:50.179958Z",
     "start_time": "2024-05-06T23:46:50.166621Z"
    }
   },
   "source": [
    "fitype(image1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1660b470e5173fe1",
   "metadata": {},
   "source": [
    "## Join layers: Original + Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "314dc9980921579e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:45:38.432917Z",
     "start_time": "2024-05-06T20:45:38.411973Z"
    }
   },
   "source": [
    "# 2 ndarrays expected\n",
    "def save_joined_layers_tensor(layers_image, layers_seg, filename):\n",
    "    tensor = torch.tensor(np.concatenate([layers_image, layers_seg], axis=2))\n",
    "    torch.save(tensor, f\"img/output/{filename}.pt\")\n",
    "save_joined_layers_tensor(array1, layers1, \"frame_0015\")\n",
    "save_joined_layers_tensor(array2, layers2, \"frame_0016\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "accbb2bc941409cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:46:15.310543Z",
     "start_time": "2024-05-03T20:46:15.296369Z"
    }
   },
   "source": [
    "layers.shape\n",
    "HEAD_DATASET"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "206a19d21dbe3aa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:47:45.894166Z",
     "start_time": "2024-05-03T20:47:45.870459Z"
    }
   },
   "source": [
    "segmented_image = render_segmentation(layers[3,:,:].astype(int), HEAD_DATASET)\n",
    "display(segmented_image)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "de40012e-a01e-4e73-bb71-3048f16d41c8",
   "metadata": {},
   "source": [
    "## Load pretrained segmentation model (Mask2Former)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2cbbbe-c53c-4e5b-977f-c2a7d93f4b8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:35:16.983031Z",
     "start_time": "2024-05-03T20:35:16.896310Z"
    }
   },
   "source": [
    "import dinov2.eval.segmentation_m2f.models.segmentors\n",
    "\n",
    "CONFIG_URL = f\"{DINOV2_BASE_URL}/dinov2_vitg14/dinov2_vitg14_ade20k_m2f_config.py\"\n",
    "CHECKPOINT_URL = f\"{DINOV2_BASE_URL}/dinov2_vitg14/dinov2_vitg14_ade20k_m2f.pth\"\n",
    "\n",
    "cfg_str = load_config_from_url(CONFIG_URL)\n",
    "cfg = mmcv.Config.fromstring(cfg_str, file_format=\".py\")\n",
    "\n",
    "model = init_segmentor(cfg)\n",
    "load_checkpoint(model, CHECKPOINT_URL, map_location=\"cpu\")\n",
    "model.cuda()\n",
    "model.eval()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "53c0309f-df2b-4912-bca5-e57d8b3875b3",
   "metadata": {},
   "source": [
    "## Semantic segmentation on sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4abb13b-0e5a-4a40-8d44-21da4286ba7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T02:42:22.685139Z",
     "start_time": "2024-03-09T02:42:22.685058Z"
    }
   },
   "source": [
    "array = np.array(image)[:, :, ::-1] # BGR\n",
    "segmentation_logits = inference_segmentor(model, array)[0]\n",
    "segmented_image = render_segmentation(segmentation_logits, \"ade20k\")\n",
    "display(segmented_image)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
